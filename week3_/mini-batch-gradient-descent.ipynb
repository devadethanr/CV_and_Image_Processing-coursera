{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.0-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dev\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.2.0-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 656.4 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/2.4 MB 819.2 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.4 MB 1.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.2.0\n"
     ]
    }
   ],
   "source": [
    "#using pytorch\n",
    "\n",
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_error_surfaces(object):\n",
    "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B  = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)\n",
    "        Z = np.zeros((30, 30))\n",
    "        count1 = 0\n",
    "        \n",
    "        self.y = Y.numpy()\n",
    "        self.x = X.numpy()\n",
    "        \n",
    "        for w1, b1 in zip(w, b):\n",
    "            count2 = 0\n",
    "            for w2, b2 in zip(w1, b1):\n",
    "                yhat = 1/(1 + np.exp(-1*(w2*self.x + b2)))\n",
    "                Z[count1, count2] = -1*np.mean(self.y*np.log(yhat+1e-16) + (1-self.y)*np.log(1-yhat+1e-16))\n",
    "                count2 += 1\n",
    "        self.Z = Z\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        self.LOSS = []\n",
    "        self.n = 0\n",
    "        if go == True:\n",
    "            plt.figure()\n",
    "            plt.figure(figsize=(7.5, 5))\n",
    "            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "            plt.title('Loss Surface')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.title('Loss Surface Contour')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.contour(self.w, self.b, self.Z)\n",
    "            plt.show()\n",
    "            \n",
    "    def set_para_loss(self, model, loss):\n",
    "        self.n = self.n + 1\n",
    "        self.LOSS.append(loss)\n",
    "        self.W.append(list(model.parameters())[0].item())\n",
    "        self.B.append(list(model.parameters())[1].item())\n",
    "        \n",
    "    def final_plot(self):\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.plot_wireframe(self.w, self.b, self.Z)\n",
    "        ax.scatter(self.W, self.B, self.LOSS, c='r', marker='x', s=200, alpha=1)\n",
    "        plt.figure()\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c='r', marker='x')\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_ps(self):\n",
    "        plt.subplot(121)\n",
    "        plt.ylim\n",
    "        plt.plot(self.x[self.y==0], self.y[self.y==0], 'ro', label=\"training points\")\n",
    "        plt.plot(self.x[self.y==1], self.y[self.y==1]-1, 'o', label=\"training points\")\n",
    "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label=\"estimated line\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim((-0.1, 2))\n",
    "        plt.title('Data Space Iteration: ' + str(self.n))\n",
    "        plt.show()\n",
    "        plt.subplot(122)\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c='r', marker='x')\n",
    "        plt.title('Loss Surface Contour Iteration' + str(self.n))\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')   \n",
    "        \n",
    "    def PlotStuff(X, Y, model, epoch, leg=True):\n",
    "        plt.plot(X.numpy(), model(X).detach().numpy(), label='epoch ' + str(epoch))\n",
    "        plt.plot(X.numpy(), Y.numpy(), 'r')\n",
    "        if leg == True:\n",
    "            plt.legend()\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17a7f2afb70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set a random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom Data class which inherits Dataset\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        # Create X values from -1 to 1 with step .1\n",
    "        self.x = torch.arange(-1, 1, 0.1).view(-1, 1)\n",
    "        # Create Y values all set to 0\n",
    "        self.y = torch.zeros(self.x.shape[0], 1)\n",
    "        # Set the X values above 0.2 to 1\n",
    "        self.y[self.x[:, 0] > 0.2] = 1\n",
    "        # Set the .len attribute because we need to override the __len__ method\n",
    "        self.len = self.x.shape[0]\n",
    "    \n",
    "    # Getter that returns the data at the given index\n",
    "    def __getitem__(self, index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get length of the dataset\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera index 0 is available\n",
      "Camera index 1 is not available\n",
      "Camera index 2 is not available\n",
      "Camera index 3 is not available\n",
      "Camera index 4 is not available\n",
      "Camera index 5 is not available\n",
      "Camera index 6 is not available\n",
      "Camera index 7 is not available\n",
      "Camera index 8 is not available\n",
      "Camera index 9 is not available\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "\n",
    "# def list_camera_indices():\n",
    "#     # Iterate over a range of possible camera indices\n",
    "#     for i in range(10):\n",
    "#         # Initialize a VideoCapture object with the current index\n",
    "#         cap = cv2.VideoCapture(i)\n",
    "        \n",
    "#         # Check if the camera is opened successfully\n",
    "#         if cap.isOpened():\n",
    "#             print(f\"Camera index {i} is available\")\n",
    "#             # Release the VideoCapture object\n",
    "#             cap.release()\n",
    "#         else:\n",
    "#             print(f\"Camera index {i} is not available\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     list_camera_indices()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
